# 调研综述

## 前言

在全球范围内土地分类这个课题中，目前对于地图块的分类主要使用的是迁移模型，无法很好的结合POI数据。POI数据是一种包含名称、类别、坐标、分类的点集合，因为在不同的地块中POI数据的种类，数量不尽相同，属于非结构数据，而传统的神经网络无法很好的学习非结构数据中的信息，所以无法将POI数据中的信息充分应用到地图块分类中。而图神经网络是处理图这种非欧几里得域最有效的一种神经网络，能很好地处理与图这种数据结构有关的任务。

所以本次调研主要目的是了解图神经网络的相关资料和最新的进展，探究怎样使用图神经网络将任务中的POIs数据和高分图像结合起来判断地块种类。



## 正文

### 1. 研究历史

#### 1.1 研究简史

Sperduti等人(1997)首次将神经网络应用于有向无环图，这推动了对GNNs的早期研究。[1]

2005年，Gori等人最初提出图神经网络的概念[2]，2009年 Scarselli等人对图神经网络做了进一步阐述，并提出了原始的图神经网络（GNN）[3]。原始的GNN网络通过迭代的方式传播邻节点信息，不断用邻节点的信息来更新目标节点的表示，直到到达一个稳定的不动点为止。通过这种方式网络能很好地学习到固定结构数据中包含的信息，但是对于非结构数据不能很好的处理。

受到CNNs在计算机视觉领域的成功，在图结构上重新定义卷积概念的方法出现。卷积图神经网路（CGNN）主要分为两类:基于谱的方法和基于空间的方法。2013年， Bruna等人提出了基于谱图理论的图卷积[4]。从这种方法开端开始，对基于频谱的CGNN有了越来越多的改进、扩展和近似[5]，[6]，[7]，[8] 。空间基卷积的研究比光谱基卷积的研究早得多。2009年，Micheli等人[9]首先在继承原始的GNN中的消息传递思想的同时，通过在架构上复合非递归层来解决图的相互依赖，但是这种方法的研究一直沉寂。但由于谱方法通常同时处理整个图，并且难以并行或扩展到大图上，所以直到最近基于空间的图卷积网络才开始快速发展，出现了许多基于空间的CGNN[10]、[11]、[12]。

在过去的几年中还开发了许多不同种类的GNNs，这些方法包括图注意力网络(GAT)、图自编码器(GAE)、图时空网络(STGNNs)。

#### 1.2 相关研究

##### 1.2.1 Graph embedding

Graph embedding是另一个到数据挖掘和机器学习社区关注的话题[13]、[14]、[15]。Graph embedding旨在将图表示为低维向量表示,维护网络拓扑结构和节点内容信息,以便任何后续图像分析任务,如分类、聚类。与此同时，GNN是一种深度学习模型，GNN旨在以端到端方式解决与图形相关的任务。许多GNN显式地提取高级表示。GNN与网络嵌入的主要区别在于，GNN是针对各种任务而设计的一组神经网GNN络模型，而网络嵌入涵盖了针对同一任务的各种方法。因此，GNNs可以通过一个图形自动编码器框架来解决网络嵌入问题。另一方面，网络嵌入还包含其他非深度学习方法，如矩阵分解[16]、随机漫步[17]。

##### 1.2.2 Graph kernel

Graph kernel是解决图分类[18]问题的主要技术。这些方法使用一个核函数来度量图对之间的相似性，直接面向图结构数据，既保留了核函数计算高效的优点，又包含了图数据在希尔伯特高维空间的结构化信息，针对不同的图结构有不同的Graph kernel。这样基于核的算法就可以用于图的监督学习。与Graph embedding类似，Graph kernel可以通过映射函数将图或节点嵌入到向量空间中。不同的是，这个映射函数是确定性的，而不是可学习的。由于图核方法采用两两相似度计算，因此存在较大的计算瓶颈。一方面，gnn直接根据所提取的图表示进行图分类，因此比图核方法效率高得多。



### 2. 研究现状

#### 2.1 研究现状

因为在图神经网络的研究上不再局限于原始GNN的改进，不同的思想与不同方法涌现而出，在图神经网络上大量的方法并行研究，所以为了更好的总结图神经网络的现状根据不同的图的种类，不同的传播方法和不同的训练方法。目前的图神经网络的研究主要分为下图所示的分类中：

![image-20200827045903482](./figure1.png)



##### 2.2.1 根据不同的图的种类

**1）Directed Graphs**

图的第一种变体是有向图。无向边可以看成是两条有向边，说明两个节点之间存在关联。有向边比无向边能带来更多的信息。因为有向图的单一性，需要区别对待主动方与被动方信息传播过程。DGP[19]采用了两种权重矩阵，以包含更精确的结构信息。

**2）Heterogeneous Graphs**

图的第二种变体是异构图，异构图中有多种节点。处理异构图最简单的方法是将每个节点的类型转换为与原始特征连接的ont-hot特征向量。此外，GraphInception[20]在异构图的传播中引入了元映射的概念。使用metapath，我们可以根据节点类型和距离对邻居进行分组。对于每个相邻组，GraphInception将其视为同构图中的子图来进行传播，并将来自不同同构图的传播结果连接起来，以进行集体节点表示。[21]最近提出了利用节点级和语义级关注的异构图注意网络(HAN)。该模型具有同时考虑节点重要性和元路径的能力。

**3）Graphs with Edge Information**

在图的另一种变体中，每条边都有额外的信息，比如权值或边的类型。有两种方式来处理这类图

1）可以将图转换成两偶图原边也成为节点和一个原边分成两个新的边缘这意味着有两个边缘之间的边缘节点和开始/结束节点[22], G2S使用的就是这种方法。

2）可以采用不同的权矩阵在不同的边上进行传播。当关系数量很大时，r-GCN[39]引入了两种正则化方法来减少关系数量建模的参数数量: *basis*- and *block-diagonal*-decomposition

**4）Dynamic Graphs**

图的另一种变体是动态图，它具有静态图结构和动态输入信号。为了捕获这两种信息，DCRNN[26]和STGCN[23]首先通过GNNs收集空间信息，然后将其输出输入序列模型，如序列对序列模型或CNNs。不同的是，Structural-RNN[24]和ST-GCN[25]同时收集空间和时间消息。它们利用时间连接对静态图结构进行扩展，从而可以在扩展后的图上应用传统的gnn。



##### **2.2.2 根据不同的传播方式** 

**1）Convolution**

这方面的进展通常分为光谱方法和非光谱(空间)方法。

其中光谱方法使用图形的光谱表示来进行学习。光谱方法的主要挑战是运算的速度和扩展性。

非光谱方法直接在图上定义卷积，作用于空间上的近邻。非光谱方法的主要挑战是定义具有不同大小邻域的卷积运算以及保持cnn的局部不变性。

**a. Spectral Network.**

- Spectral Network*. [27] 通过计算图的拉普拉斯特征分解，在傅里叶域中定义了卷积运算。


* ChebNet*. [28]它使用*K*-localized卷积来定义卷积神经网络，它可以消除计算拉普拉斯特征向量的需要。

- *GCN.* [29]将分层卷积操作限制在K = 1，以缓解节点度分布非常宽的图的局部邻域结构过拟合问题。
- *AGCN*. [30] 尝试区别不同节点之间的隐式关系，AGCN学习一个“残差”图的拉普拉斯矩阵，并将其添加到原始的拉普拉斯矩阵中。

- *GGP*. [31] 解决半监督学习问题。它显示了模型和光谱滤波方法之间的相似性

**b. Non-spectral Network**

- *Neural FPs*. [32] 对不同程度的节点使用不同的权值矩阵

- *DCNN*. [23] 使用转换矩阵来定义节点的邻域。

- *DGCN*. [33] 联合考虑图上的局部一致性和全局一致性。该算法使用两个卷积网络捕获局部/全局一致性，并采用无监督损失对其进行集成。

- PATCHY-SAN。[34]对每个节点提取并归一化一个k个节点的邻域。归一化邻域作为卷积操作的感受域。

- LGCN。[35]也利用cnn作为聚合器。对节点邻域矩阵进行最大pooling，得到top-k特征元素，然后应用CNN计算隐藏表示。

- *MoNet*。[22]提出了一个非欧几里得区域的空间域模型，它可以推广之前的一些技术。GCNN[24]和ACNN，GCN[2]和DCNN[23]，都可以表示为*MoNet*的特殊实例。
- GraphSAGE。[1]提出了一个通用的归纳框架。该框架通过从节点的本地邻域采样和聚合特征来生成嵌入。但是该模型没有利用中邻居的全部集合而是通过均匀抽样得到的固定大小的邻居集合。


**2）Gate**

有许多方法试图在传播步骤中使用gate机制，如GRU[57]或LSTM[58]，以减少前GNN模型中的限制，并改进信息在图结构中的长期传播。

**a. GRU**

- *GGNN*. [59]提出了门控图神经网络(GGNN)，该网络在传播步骤中使用门控递归单元(GRU)，将递归单元展开到固定的步骤T，并通过时间反向传播来计算梯度。

**b. LSTM**

- *Tree-LSTM*. [60]对基本的LSTM体系结构提出了两个扩展: *Child-Sum Tree-LSTM* 和the *N-ary Tree-LSTM*。
- *Sentence LSTM* (S-LSTM). [62]提出了句子LSTM (S-LSTM)来改进文本编码。它将文本转换为图，并利用图的LSTM来学习图的表示。的S-LSTM在许多神经规划问题中表现出很强的表示能力。

- *Graph LSTM* . [63]提出了一个图LSTM网络来解决语义对象解析任务。它使用了trustencedriven方案自适应地选择起始节点，确定节点的更新顺序。

**3）Attention.**

注意机制在许多基于序列的任务上有成功的应用，[68]提出了一种图注意网络(GAT)，它将注意机制纳入传播步骤。它通过关注它的邻居来计算每个节点的隐藏状态，遵循一个自我关注策略。

**4） Skip connection.**

许多应用程序展开或堆叠图神经网络层，以达到更好的结果，因为更多的层(即k层)使每个节点从相邻k跳转移来聚合更多的信息。然而，在许多实验中观察到，更深层的模型并不能提高性能，甚至可以使网络的性能更差。

[74]研究了邻域聚集方案的性质及其局限性。它提议Jump Knowledge Network，这是一种能够学习自适应、结构感知表征的知识网络。跳转知识网络从所有的中间表示中进行选择对最后一层的每个节点进行“跳转”，使得模型根据需要调整每个节点的有效邻域大小。

**5）Hierarchical Pooling.**

在计算机视觉领域，卷积层之后通常是池化层，以获得更一般的特征。与这些池化层类似，很多工作都集中于在图上设计分层池化层。复杂、大规模的图通常具有丰富的层次结构，这对于节点级和图级分类任务具有重要意义。



##### 2.2.1 根据不同的训练方法

原有的图卷积神经网络在训练和优化方法上存在一些缺陷。GCN需要完整的Laplacian图，对于大型图来说这需要大量的计算。此外，节点在L层的嵌入是通过其所有邻居在L -1层的嵌入来递归计算的。因此，单个节点的接受域相对于层数呈指数增长，因此计算单个节点的梯度代价较大。所以需要使用更加有效率的方法来进行训练。以下为三种主要的训练方式

**1）Sampling.**

**2）Data Augmentation.**

**3）Unsupervised Training.** 



### 3. 研究关联

在我们研究需要的领域主要是将图神经网络应用在我们的遥感高分图像和POI数据相结合的分类中，所以我主要调研的是图神经网路在图像分类领域中的相关研究。

在图像分类领域，主要是结合知识图将 利用图形神经网络在图像分类中合并结构信息。知识图可以作为额外的信息来指导零短识别分类[35]，[37]。

[37]构建每个节点对应一个对象类别的知识图，并将节点的单词嵌入作为输入，用于预测不同类别的分类器。由于卷积结构的深度会产生过平滑的效果，在网络中中使用的6层GCN会在表示中冲刷掉很多有用的信息。

[35]使用了具有较大邻域的单层GCN，图中既有单跳节点，也有多跳节点。用已有的零粒分类器构造零粒分类器是有效的。解决了GCN传播过程中的平滑问题

数据集中图像之间的相似性也有助于few-shot的学习[36] [38] [39]。

[36]提出基于相似度构建加权全连通图像网络，在图中传递消息进行少镜头识别。

[39]根据目标检测的结果，选择一些相关实体构建子图，并将GGNN应用于所提取的图进行预测。

[38]提出构建新的知识图，其中实体为所有类别。并且，他们定义了三种类型的标签关系:上级关系、正相关关系、负相关关系，并直接在图中传播标签的置信度。



### 4. 可能应用

#### 4.1 将POIs数据作为知识图

在文献The more you know: Using knowledge graphs for image classification[39]中

其中是根据目标检测结果，选择一些相关实体通过结构之间的关系包括，从属，包含等关系构建子图，并将GGNN应用于所提取的图，采用图分类的方式构建子图。文献中一个示例：对于一张小鼠的图片，通过识别小鼠的鼻子，尾巴，毛发，脚等部分信息，将这些信息通过图的方式，使用包含，属于等关系连接起来。最后通过GGNN图神经网络做图分类，以图的分类结果作为图像的分类结果。

对应到我们的项目的需求，我们也可以通过结合POI数据和图像数据结合在一起，用POI数据作为子图连接。POI中的每一个点都有自己的属性，每个分类和每个POI之间点的关系可以直接联合构成子图用来判断我们的地图块分类。



#### 4.2 将POIs数据结合图像数据作为知识图

根据4.1中的思路，同样可以将图像数据和POIs数据结合起来，首先通过识别图像上的包括纹理、结构、特殊事件等信息，将这些信息通过相同的包括、包含、从属等关系连接成子图，将整个图作为图分类神经网络的输入，将最后的输出结果作为参考。



### 5. 发展趋势

#### 5.1 加深网络

深度学习的成功在于深度神经架构。例如在图像分类中，模型ResNet具有152层。但在图网络中，实证研究表明，随着网络层数增加，模型性能急剧下降。根据论文[65]，这是由于图卷积的影响，因为它本质上推动相邻节点的表示更加接近彼此，所以理论上，通过无限次卷积，所有节点的表示将收敛到一个点。这导致了一个问题：加深网络是否仍然是学习图结构数据的好策略？

#### 5.2 增加感受视野

节点的感受野是指一组节点，包括中心节点和其近邻节点。节点的近邻（节点）数量遵循幂律分布。有些节点可能只有一个近邻，而有些节点却有数千个近邻。尽管采用了采样策略 [66],[67],[68]，但如何选择节点的代表性感受野仍然有待探索。

#### 5.3 可扩展性

大部分图神经网络并不能很好地扩展到大型图上。主要原因是当堆叠一个图卷积的多层时，节点的最终状态涉及其大量近邻节点的隐藏状态，导致反向传播变得非常复杂。虽然有些方法试图通过快速采样和子图训练来提升模型效[66], [68]，但它们仍无法扩展到大型图的深度架构上。

#### 5.4 动态性和异质性

大多数当前的图神经网络都处理静态同质图。一方面，假设图架构是固定的。另一方面，假设图的节点和边来自同一个来源。然而，这两个假设在很多情况下是不现实的。在社交网络中，一个新人可能会随时加入，而之前就存在的人也可能退出该社交网络。在推荐系统中，产品可能具有不同的类型，而其输出形式也可能不同，也许是文本，也许是图像。因此，应当开发新方法来处理动态和异质图结构。



## 总结

在过去几年中，图形神经网络已成为图域中机器学习任务的强大而实用的工具。这一进展归功于表现力，模型灵活性和训练算法的进步。对于GNN模型，我大概总结了几个通用框架，以统一表示不同的变体。在研究热点方面，我大概将GNN应用程序划分为结构场景，非结构场景和其他场景，然后对每个场景中具体热点进行了讨论研究。最后提出了下一步研究趋势，指出了图神经网络的主要挑战和未来研究方向，包括模型深度，可扩展性，处理动态图和非结构场景的能力。





## 参考文献

[1] A. Sperduti and A. Starita, “Supervised neural networks for the classification of structures,” *IEEE Transactions on Neural Networks*, vol. 8, no. 3, pp. 714–735, 1997

[2] M. Gori, G. Monfardini, and F. Scarselli, “A new model for learning in graph domains,” in *Proc. of IJCNN*, vol. 2. IEEE, 2005, pp. 729–734.

[3] F. Scarselli, M. Gori, A. C. Tsoi, M. Hagenbuchner, and G. Monfardini, “The graph neural network model,” *IEEE Transactions on Neural*

 Networks*, vol. 20, no. 1, pp. 61–80, 2009.

[4] J. Bruna, W. Zaremba, A. Szlam, and Y. LeCun, “Spectral networks and locally connected networks on graphs,” in *Proc. of ICLR*, 2014.

[5] M. Henaff, J. Bruna, and Y. LeCun, “Deep convolutional networks on graph-structured data,” *arXiv preprint arXiv:1506.05163*, 2015.

[6] M. Defferrard, X. Bresson, and P. Vandergheynst, “Convolutional neural networks on graphs with fast localized spectral filtering,” in *Proc. of NIPS*, 2016, pp. 3844–3852.

[7] T. N. Kipf and M. Welling, “Semi-supervised classification with graph convolutional networks,” in *Proc. of ICLR*, 2017.

[8] R. Levie, F. Monti, X. Bresson, and M. M. Bronstein, “Cayleynets: Graph convolutional neural networks with complex rational spectral filters,” *IEEE Transactions on Signal Processing*, vol. 67, no. 1, pp. 97–109, 2017.

[9] A. Micheli, “Neural network for graphs: A contextual constructive approach,” *IEEE Transactions on Neural Networks*, vol. 20, no. 3, pp.498–511, 2009.

[10] J. Atwood and D. Towsley, “Diffusion-convolutional neural networks,” in *Proc. of NIPS*, 2016, pp. 1993–2001.

[11] M. Niepert, M. Ahmed, and K. Kutzkov, “Learning convolutional neural networks for graphs,” in *Proc. of ICML*, 2016, pp. 2014–2023.

[12] J. Gilmer, S. S. Schoenholz, P. F. Riley, O. Vinyals, and G. E. Dahl, “Neural message passing for quantum chemistry,” in *Proc. of ICML*, 2017, pp. 1263–1272.

[13] W. L. Hamilton, R. Ying, and J. Leskovec, “Representation learning on graphs: Methods and applications,” in *Proc. of NIPS*, 2017, pp. 1024–1034.

[14] P. Cui, X. Wang, J. Pei, and W. Zhu, “A survey on network embedding,” IEEE Transactions on Knowledge and Data Engineering*, 2017.

[15] D. Zhang, J. Yin, X. Zhu, and C. Zhang, “Network representation learning: A survey,” *IEEE Transactions on Big Data*, 2018.

[16] H. Yang, S. Pan, P. Zhang, L. Chen, D. Lian, and C. Zhang, “Binarized attributed network embedding,” in *Proc. of ICDM*. IEEE, 2018.

[17] B. Perozzi, R. Al-Rfou, and S. Skiena, “Deepwalk: Online learning of social representations,” in *Proc. of KDD*. ACM, 2014, pp. 701–710.

[18] S. V. N. Vishwanathan, N. N. Schraudolph, R. Kondor, and K. M. Borgwardt, “Graph kernels,” *Journal of Machine Learning Research*, vol. 11, no. Apr, pp. 361–1242, 2010.

[19] M. Kampffmeyer, Y. Chen, X. Liang, H. Wang, Y. Zhang, and E. P. Xing, “Rethinking knowledge graph propagation for zero-shot learning,” *arXiv preprint arXiv:1805.11724*, 2018.

[20] Y. Zhang, Y. Xiong, X. Kong, S. Li, J. Mi, and Y. Zhu, “Deep collective classifification in heterogeneous information networks,” in *WWW 2018*, 2018, pp. 399–408.

[21] X. Wang, H. Ji, C. Shi, B. Wang, Y. Ye, P. Cui, and P. S. Yu, “Heterogeneous graph attention network,” *WWW 2019*, 2019.

[22] D. Beck, G. Haffari, and T. Cohn, “Graph-to-sequence learning using gated graph neural networks,” in *ACL 2018*, 2018, pp. 273–283.

[23] B. Yu, H. Yin, and Z. Zhu, “Spatio-temporal graph convolutional networks: A deep learning framework for traffific forecasting,” arXiv preprint arXiv:1709.04875*, 2017.20

[24] A. Jain, A. R. Zamir, S. Savarese, and A. Saxena, “Structural-rnn: Deep learning on spatio-temporal graphs,” in *CVPR 2016*, 2016, pp. 5308–5317.

[25] S. Yan, Y. Xiong, and D. Lin, “Spatial temporal graph convolu-tional networks for skeleton-based action recognition,” in *Thirty-Second AAAI Conference on Artifificial Intelligence*, 2018.

[26] Y. Li, R. Yu, C. Shahabi, and Y. Liu, “Diffusion convolutional recurrent neural network: Data-driven traffific forecasting,” *arXiv* *preprint arXiv:1707.01926*, 2017.

[27] J. Bruna, W. Zaremba, A. Szlam, and Y. Lecun, “Spectral networks

and locally connected networks on graphs,” *ICLR 2014*, 2014.

[28] M. Defferrard, X. Bresson, and P. Vandergheynst, “Convolutional neural networks on graphs with fast localized spectral fifiltering,” NIPS 2016*, pp. 3844–3852, 2016.

[29] T. N. Kipf and M. Welling, “Semi-supervised classifification with-graph convolutional networks,” *ICLR 2017*, 2017.

[30] R. Li, S. Wang, F. Zhu, and J. Huang, “Adaptive graph convolu-tional neural networks,” in *AAAI 2018*, 2018.

[31] Y. C. Ng, N. Colombo, and R. Silva, “Bayesian semi-supervised learning with graph gaussian processes,” in *NeurIPS 2018*, 2018, pp. 1690–1701.

[32] D. K. Duvenaud, D. Maclaurin, J. Aguileraiparraguirre, R. Gomezbombarelli, T. D. Hirzel, A. Aspuruguzik, and R. P. Adams, “Convolutional networks on graphs for learning molec-ular fifingerprints,” *NIPS 2015*, pp. 2224–2232, 2015.

[33] C. Zhuang and Q. Ma, “Dual graph convolutional networks for graph-based semi-supervised classifification,” in *WWW 2018*, 2018.

[34] M. Niepert, M. Ahmed, and K. Kutzkov, “Learning convolutional neural networks for graphs,” in *ICML 2016*, 2016, pp. 2014–2023.

[35] H. Gao, Z. Wang, and S. Ji, “Large-scale learnable graph convo-lutional networks,” in *Proceedings of SIGKDD*. ACM, 2018, pp. 1416–1424.

[36] V. Garcia and J. Bruna, “Few-shot learning with graph neural networks,” *arXiv preprint arXiv:1711.04043*, 2017.

[37] X. Wang, Y. Ye, and A. Gupta, “Zero-shot recognition via semantic embeddings and knowledge graphs,” in *CVPR 2018*, 2018, pp.6857–6866.

[38] C. Lee, W. Fang, C. Yeh, and Y. F. Wang, “Multi-label zero-shot learning with structured knowledge graphs,” in *Proceedings of* *CVPR*, 2018, pp. 1576–1585.

[39] K. Marino, R. Salakhutdinov, and A. Gupta, “The more you know: Using knowledge graphs for image classification,” in *Proceedings of CVPR*, 2017, pp. 20–28.